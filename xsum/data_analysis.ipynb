{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ppoulos/miniconda3/envs/pavlosEnv2/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from datasets import load_dataset\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from transformers import AutoTokenizer, DataCollatorForSeq2Seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = \"xsum\"\n",
    "seed_num = 1\n",
    "model_name = \"google-t5/t5-small\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading builder script: 100%|██████████| 5.76k/5.76k [00:00<00:00, 10.7MB/s]\n",
      "Downloading readme: 100%|██████████| 6.24k/6.24k [00:00<00:00, 12.5MB/s]\n",
      "Downloading data: 100%|██████████| 255M/255M [01:08<00:00, 3.71MB/s] \n",
      "Downloading data: 2.72MB [00:00, 16.1MB/s]                           \n",
      "Generating train split: 100%|██████████| 204045/204045 [00:32<00:00, 6185.20 examples/s]\n",
      "Generating validation split: 100%|██████████| 11332/11332 [00:18<00:00, 611.31 examples/s]\n",
      "Generating test split: 100%|██████████| 11334/11334 [00:18<00:00, 611.93 examples/s]\n"
     ]
    }
   ],
   "source": [
    "loaded_dataset = load_dataset(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['document', 'summary', 'id'],\n",
       "        num_rows: 204045\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['document', 'summary', 'id'],\n",
       "        num_rows: 11332\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['document', 'summary', 'id'],\n",
       "        num_rows: 11334\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_dataset\n",
    "# make the dataset into a pandas dataframe\n",
    "# df = pd.DataFrame(loaded_dataset['train'])\n",
    "# # add the test dataset to the dataframe\n",
    "# df = pd.concat([df, pd.DataFrame(loaded_dataset['test'])], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize the summary column\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map:   0%|          | 0/204045 [00:00<?, ? examples/s]Token indices sequence length is longer than the specified maximum sequence length for this model (541 > 512). Running this sequence through the model will result in indexing errors\n",
      "Map: 100%|██████████| 204045/204045 [01:24<00:00, 2425.33 examples/s]\n",
      "Map: 100%|██████████| 11332/11332 [00:05<00:00, 2237.08 examples/s]\n",
      "Map: 100%|██████████| 11334/11334 [00:05<00:00, 2265.14 examples/s]\n"
     ]
    }
   ],
   "source": [
    "prefix = \"summarize: \"  # Required so the T5 model knows that we are going to summarize\n",
    "def preprocess_function(examples):\n",
    "    inputs = [prefix + doc for doc in examples[\"document\"]]\n",
    "    model_inputs = tokenizer(inputs)\n",
    "    labels = tokenizer(text_target=examples[\"summary\"])\n",
    "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
    "    return model_inputs\n",
    "\n",
    "data_collator = DataCollatorForSeq2Seq(tokenizer=tokenizer, model=model_name)\n",
    "tokenized_dataset = loaded_dataset.map(preprocess_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>document</th>\n",
       "      <th>summary</th>\n",
       "      <th>id</th>\n",
       "      <th>input_ids</th>\n",
       "      <th>attention_mask</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>204040</th>\n",
       "      <td>The initial figure released in July was booste...</td>\n",
       "      <td>UK economic growth for the second quarter of t...</td>\n",
       "      <td>34084759</td>\n",
       "      <td>[21603, 10, 37, 2332, 2320, 1883, 16, 1718, 47...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[1270, 1456, 1170, 21, 8, 511, 2893, 13, 8, 21...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204041</th>\n",
       "      <td>MEPs, including European Parliament chief Brex...</td>\n",
       "      <td>Theresa May's offer to give EU citizens in the...</td>\n",
       "      <td>40552318</td>\n",
       "      <td>[21603, 10, 283, 8569, 7, 6, 379, 1611, 12876,...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[290, 7, 9, 932, 31, 7, 462, 12, 428, 3371, 51...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204042</th>\n",
       "      <td>Lincoln Red Imps will bring a 1-0 lead to Glas...</td>\n",
       "      <td>Erik Sviatchenko is adamant that Celtic will p...</td>\n",
       "      <td>36781065</td>\n",
       "      <td>[21603, 10, 9884, 1624, 14472, 7, 56, 830, 3, ...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[21173, 180, 2099, 14547, 18994, 19, 3, 9, 781...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204043</th>\n",
       "      <td>Former Liverpool defender Mark Lawrenson expan...</td>\n",
       "      <td>People have spent a large part of this season ...</td>\n",
       "      <td>31579588</td>\n",
       "      <td>[21603, 10, 18263, 15131, 3, 13720, 2185, 2402...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[2449, 43, 1869, 3, 9, 508, 294, 13, 48, 774, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204044</th>\n",
       "      <td>The incident occurred at the headquarters of t...</td>\n",
       "      <td>Police in Thailand have charged two executives...</td>\n",
       "      <td>35809055</td>\n",
       "      <td>[21603, 10, 37, 5415, 6935, 44, 8, 13767, 13, ...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[5076, 16, 10508, 43, 4977, 192, 13510, 45, 3,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 document  \\\n",
       "204040  The initial figure released in July was booste...   \n",
       "204041  MEPs, including European Parliament chief Brex...   \n",
       "204042  Lincoln Red Imps will bring a 1-0 lead to Glas...   \n",
       "204043  Former Liverpool defender Mark Lawrenson expan...   \n",
       "204044  The incident occurred at the headquarters of t...   \n",
       "\n",
       "                                                  summary        id  \\\n",
       "204040  UK economic growth for the second quarter of t...  34084759   \n",
       "204041  Theresa May's offer to give EU citizens in the...  40552318   \n",
       "204042  Erik Sviatchenko is adamant that Celtic will p...  36781065   \n",
       "204043  People have spent a large part of this season ...  31579588   \n",
       "204044  Police in Thailand have charged two executives...  35809055   \n",
       "\n",
       "                                                input_ids  \\\n",
       "204040  [21603, 10, 37, 2332, 2320, 1883, 16, 1718, 47...   \n",
       "204041  [21603, 10, 283, 8569, 7, 6, 379, 1611, 12876,...   \n",
       "204042  [21603, 10, 9884, 1624, 14472, 7, 56, 830, 3, ...   \n",
       "204043  [21603, 10, 18263, 15131, 3, 13720, 2185, 2402...   \n",
       "204044  [21603, 10, 37, 5415, 6935, 44, 8, 13767, 13, ...   \n",
       "\n",
       "                                           attention_mask  \\\n",
       "204040  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "204041  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "204042  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "204043  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "204044  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "\n",
       "                                                   labels  \n",
       "204040  [1270, 1456, 1170, 21, 8, 511, 2893, 13, 8, 21...  \n",
       "204041  [290, 7, 9, 932, 31, 7, 462, 12, 428, 3371, 51...  \n",
       "204042  [21173, 180, 2099, 14547, 18994, 19, 3, 9, 781...  \n",
       "204043  [2449, 43, 1869, 3, 9, 508, 294, 13, 48, 774, ...  \n",
       "204044  [5076, 16, 10508, 43, 4977, 192, 13510, 45, 3,...  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make the dataset into a Dataframe\n",
    "df = pd.DataFrame(tokenized_dataset['train'])\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('The full cost of damage in Newton Stewart, one of the areas worst affected, '\n",
      " 'is still being assessed.\\n'\n",
      " 'Repair work is ongoing in Hawick and many roads in Peeblesshire remain badly '\n",
      " 'affected by standing water.\\n'\n",
      " 'Trains on the west coast mainline face disruption due to damage at the '\n",
      " 'Lamington Viaduct.\\n'\n",
      " 'Many businesses and householders were affected by flooding in Newton Stewart '\n",
      " 'after the River Cree overflowed into the town.\\n'\n",
      " 'First Minister Nicola Sturgeon visited the area to inspect the damage.\\n'\n",
      " 'The waters breached a retaining wall, flooding many commercial properties on '\n",
      " 'Victoria Street - the main shopping thoroughfare.\\n'\n",
      " 'Jeanette Tate, who owns the Cinnamon Cafe which was badly affected, said she '\n",
      " 'could not fault the multi-agency response once the flood hit.\\n'\n",
      " 'However, she said more preventative work could have been carried out to '\n",
      " 'ensure the retaining wall did not fail.\\n'\n",
      " '\"It is difficult but I do think there is so much publicity for Dumfries and '\n",
      " \"the Nith - and I totally appreciate that - but it is almost like we're \"\n",
      " 'neglected or forgotten,\" she said.\\n'\n",
      " '\"That may not be true but it is perhaps my perspective over the last few '\n",
      " 'days.\\n'\n",
      " '\"Why were you not ready to help us a bit more when the warning and the alarm '\n",
      " 'alerts had gone out?\"\\n'\n",
      " 'Meanwhile, a flood alert remains in place across the Borders because of the '\n",
      " 'constant rain.\\n'\n",
      " 'Peebles was badly hit by problems, sparking calls to introduce more defences '\n",
      " 'in the area.\\n'\n",
      " 'Scottish Borders Council has put a list on its website of the roads worst '\n",
      " 'affected and drivers have been urged not to ignore closure signs.\\n'\n",
      " \"The Labour Party's deputy Scottish leader Alex Rowley was in Hawick on \"\n",
      " 'Monday to see the situation first hand.\\n'\n",
      " 'He said it was important to get the flood protection plan right but backed '\n",
      " 'calls to speed up the process.\\n'\n",
      " '\"I was quite taken aback by the amount of damage that has been done,\" he '\n",
      " 'said.\\n'\n",
      " '\"Obviously it is heart-breaking for people who have been forced out of their '\n",
      " 'homes and the impact on businesses.\"\\n'\n",
      " 'He said it was important that \"immediate steps\" were taken to protect the '\n",
      " 'areas most vulnerable and a clear timetable put in place for flood '\n",
      " 'prevention plans.\\n'\n",
      " 'Have you been affected by flooding in Dumfries and Galloway or the Borders? '\n",
      " 'Tell us about your experience of the situation and how it was handled. Email '\n",
      " 'us on selkirk.news@bbc.co.uk or dumfries@bbc.co.uk.')\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "pprint(df['document'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    204045.000000\n",
       "mean        525.922223\n",
       "std         438.174692\n",
       "min           3.000000\n",
       "25%         249.000000\n",
       "50%         412.000000\n",
       "75%         682.000000\n",
       "90%        1061.000000\n",
       "95%        1309.000000\n",
       "99%        1937.000000\n",
       "max       39490.000000\n",
       "Name: input_ids, dtype: float64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Give me the percentiles of length of input_ids using pandas and plot them\n",
    "df['input_ids'].apply(len).describe(percentiles=[0.25, 0.5, 0.75, 0.9, 0.95, 0.99])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    204045.000000\n",
       "mean         30.383719\n",
       "std           8.337640\n",
       "min           3.000000\n",
       "25%          25.000000\n",
       "50%          30.000000\n",
       "75%          35.000000\n",
       "90%          39.000000\n",
       "95%          43.000000\n",
       "99%          54.000000\n",
       "max         178.000000\n",
       "Name: labels, dtype: float64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The same for the labels\n",
    "df['labels'].apply(len).describe(percentiles=[0.25, 0.5, 0.75, 0.9, 0.95, 0.99])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pavlosEnv2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
