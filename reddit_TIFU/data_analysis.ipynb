{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ppoulos/miniconda3/envs/pavlosEnv2/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from datasets import load_dataset\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from transformers import AutoTokenizer, DataCollatorForSeq2Seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = \"reddit_tifu\"\n",
    "seed_num = 1\n",
    "model_name = \"google-t5/t5-small\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 100%|██████████| 42139/42139 [00:06<00:00, 6924.14 examples/s]\n"
     ]
    }
   ],
   "source": [
    "loaded_dataset = load_dataset(dataset, 'long')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['ups', 'num_comments', 'upvote_ratio', 'score', 'documents', 'tldr', 'title'],\n",
       "        num_rows: 42139\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_dataset\n",
    "# make the dataset into a pandas dataframe\n",
    "# df = pd.DataFrame(loaded_dataset['train'])\n",
    "# # add the test dataset to the dataframe\n",
    "# df = pd.concat([df, pd.DataFrame(loaded_dataset['test'])], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize the summary column\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map:   0%|          | 0/42139 [00:00<?, ? examples/s]Token indices sequence length is longer than the specified maximum sequence length for this model (892 > 512). Running this sequence through the model will result in indexing errors\n",
      "Map: 100%|██████████| 42139/42139 [00:16<00:00, 2525.35 examples/s]\n"
     ]
    }
   ],
   "source": [
    "prefix = \"summarize: \"  # Required so the T5 model knows that we are going to summarize\n",
    "def preprocess_function(examples):\n",
    "    inputs = [prefix + doc for doc in examples[\"documents\"]]\n",
    "    model_inputs = tokenizer(inputs)\n",
    "    labels = tokenizer(text_target=examples[\"tldr\"])\n",
    "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
    "    return model_inputs\n",
    "\n",
    "data_collator = DataCollatorForSeq2Seq(tokenizer=tokenizer, model=model_name)\n",
    "tokenized_dataset = loaded_dataset.map(preprocess_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ups</th>\n",
       "      <th>num_comments</th>\n",
       "      <th>upvote_ratio</th>\n",
       "      <th>score</th>\n",
       "      <th>documents</th>\n",
       "      <th>tldr</th>\n",
       "      <th>title</th>\n",
       "      <th>input_ids</th>\n",
       "      <th>attention_mask</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>42134</th>\n",
       "      <td>105.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.94</td>\n",
       "      <td>105.0</td>\n",
       "      <td>this happened back in middle school.\\n\\nmy fam...</td>\n",
       "      <td>forgot my quarter for lunch at school for a we...</td>\n",
       "      <td>forgetting my quarter for lunch</td>\n",
       "      <td>[21603, 10, 48, 2817, 223, 16, 2214, 496, 5, 8...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[15687, 82, 2893, 21, 3074, 44, 496, 21, 3, 9,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42135</th>\n",
       "      <td>96.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>0.92</td>\n",
       "      <td>96.0</td>\n",
       "      <td>my girlfriend told me she has no hair beneath ...</td>\n",
       "      <td>girlfriend prefers clean shaven groin. i try t...</td>\n",
       "      <td>trying to shave my pubes for the first time</td>\n",
       "      <td>[21603, 10, 82, 17442, 1219, 140, 255, 65, 150...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[17442, 2396, 7, 1349, 3, 7, 7965, 29, 3, 3844...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42136</th>\n",
       "      <td>726.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>0.91</td>\n",
       "      <td>726.0</td>\n",
       "      <td>today at work i accidentally crashed a row of ...</td>\n",
       "      <td>today i broke a window that costs more then i ...</td>\n",
       "      <td>breaking a $900 window with a shopping cart.</td>\n",
       "      <td>[21603, 10, 469, 44, 161, 3, 23, 21169, 24679,...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[469, 3, 23, 8238, 3, 9, 2034, 24, 1358, 72, 2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42137</th>\n",
       "      <td>26.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.77</td>\n",
       "      <td>26.0</td>\n",
       "      <td>so as u can tell from the title it didn't happ...</td>\n",
       "      <td>i invited over new girlfriend for dinner to sp...</td>\n",
       "      <td>slicing open my finger on first valentines wit...</td>\n",
       "      <td>[21603, 10, 78, 38, 3, 76, 54, 817, 45, 8, 223...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[3, 23, 5374, 147, 126, 17442, 21, 2634, 12, 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42138</th>\n",
       "      <td>15.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.81</td>\n",
       "      <td>15.0</td>\n",
       "      <td>this did actually happen today. it started aft...</td>\n",
       "      <td>in a rush i mixed my colours in the wash and e...</td>\n",
       "      <td>not listening to my mother</td>\n",
       "      <td>[21603, 10, 48, 410, 700, 1837, 469, 5, 34, 70...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[16, 3, 9, 10505, 3, 23, 4838, 82, 6548, 16, 8...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         ups  num_comments  upvote_ratio  score  \\\n",
       "42134  105.0          18.0          0.94  105.0   \n",
       "42135   96.0          64.0          0.92   96.0   \n",
       "42136  726.0         110.0          0.91  726.0   \n",
       "42137   26.0           5.0          0.77   26.0   \n",
       "42138   15.0          11.0          0.81   15.0   \n",
       "\n",
       "                                               documents  \\\n",
       "42134  this happened back in middle school.\\n\\nmy fam...   \n",
       "42135  my girlfriend told me she has no hair beneath ...   \n",
       "42136  today at work i accidentally crashed a row of ...   \n",
       "42137  so as u can tell from the title it didn't happ...   \n",
       "42138  this did actually happen today. it started aft...   \n",
       "\n",
       "                                                    tldr  \\\n",
       "42134  forgot my quarter for lunch at school for a we...   \n",
       "42135  girlfriend prefers clean shaven groin. i try t...   \n",
       "42136  today i broke a window that costs more then i ...   \n",
       "42137  i invited over new girlfriend for dinner to sp...   \n",
       "42138  in a rush i mixed my colours in the wash and e...   \n",
       "\n",
       "                                                   title  \\\n",
       "42134                    forgetting my quarter for lunch   \n",
       "42135        trying to shave my pubes for the first time   \n",
       "42136       breaking a $900 window with a shopping cart.   \n",
       "42137  slicing open my finger on first valentines wit...   \n",
       "42138                         not listening to my mother   \n",
       "\n",
       "                                               input_ids  \\\n",
       "42134  [21603, 10, 48, 2817, 223, 16, 2214, 496, 5, 8...   \n",
       "42135  [21603, 10, 82, 17442, 1219, 140, 255, 65, 150...   \n",
       "42136  [21603, 10, 469, 44, 161, 3, 23, 21169, 24679,...   \n",
       "42137  [21603, 10, 78, 38, 3, 76, 54, 817, 45, 8, 223...   \n",
       "42138  [21603, 10, 48, 410, 700, 1837, 469, 5, 34, 70...   \n",
       "\n",
       "                                          attention_mask  \\\n",
       "42134  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "42135  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "42136  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "42137  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "42138  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "\n",
       "                                                  labels  \n",
       "42134  [15687, 82, 2893, 21, 3074, 44, 496, 21, 3, 9,...  \n",
       "42135  [17442, 2396, 7, 1349, 3, 7, 7965, 29, 3, 3844...  \n",
       "42136  [469, 3, 23, 8238, 3, 9, 2034, 24, 1358, 72, 2...  \n",
       "42137  [3, 23, 5374, 147, 126, 17442, 21, 2634, 12, 1...  \n",
       "42138  [16, 3, 9, 10505, 3, 23, 4838, 82, 6548, 16, 8...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make the dataset into a Dataframe\n",
    "df = pd.DataFrame(tokenized_dataset['train'])\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('this actually happened a couple of years ago. i grew up in germany where i '\n",
      " 'went to a german secondary school that went from 5th to 13th grade (we still '\n",
      " 'had 13 grades then, they have since changed that). my school was named after '\n",
      " 'anne frank and we had a club that i was very active in from 9th grade on, '\n",
      " 'which was dedicated to teaching incoming 5th graders about anne franks life, '\n",
      " 'discrimination, anti-semitism, hitler, the third reich and that whole spiel. '\n",
      " \"basically a day where the students' classes are cancelled and instead we \"\n",
      " 'give them an interactive history and social studies class with lots of '\n",
      " 'activities and games. \\n'\n",
      " '\\n'\n",
      " 'this was my last year at school and i already had a lot of experience doing '\n",
      " 'these project days with the kids. i was running the thing with a friend, so '\n",
      " 'it was just the two of us and 30-something 5th graders. we start off with a '\n",
      " 'brief introduction and brainstorming: what do they know about anne frank and '\n",
      " \"the third reich? you'd be surprised how much they know. anyway after the \"\n",
      " 'brainstorming we do a few activities, and then we take a short break. after '\n",
      " 'the break we split the class into two groups to make it easier to handle. '\n",
      " 'one group watches a short movie about anne frank while the other gets a tour '\n",
      " 'through our poster presentation that our student group has been perfecting '\n",
      " 'over the years. then the groups switch. \\n'\n",
      " '\\n'\n",
      " \"i'm in the classroom to show my group the movie and i take attendance to \"\n",
      " \"make sure no one decided to run away during break. i'm going down the list \"\n",
      " 'when i come to the name sandra (name changed). a kid with a boyish haircut '\n",
      " \"and a somewhat deeper voice, wearing clothes from the boy's section at a big \"\n",
      " 'clothing chain in germany, pipes up. \\n'\n",
      " '\\n'\n",
      " 'now keep in mind, these are all 11 year olds, they are all pre-pubescent, '\n",
      " 'their bodies are not yet showing any sex specific features one would be able '\n",
      " 'to see while they are fully clothed (e.g. boobs, beards,...). this being a '\n",
      " '5th grade in the rather conservative (for german standards) bavaria, i was '\n",
      " 'confused. i looked down at the list again making sure i had read the name '\n",
      " 'right. look back up at the kid. \\n'\n",
      " '\\n'\n",
      " 'me: \"you\\'re sandra?\"\\n'\n",
      " '\\n'\n",
      " 'kid: \"yep.\"\\n'\n",
      " '\\n'\n",
      " 'me: \"oh, sorry. *thinking the kid must be from somewhere where sandra is '\n",
      " \"both a girl's and boy's name* where are you from? i've only ever heard that \"\n",
      " 'as a girl\\'s name before.\"\\n'\n",
      " '\\n'\n",
      " 'the class starts laughing. sandra gets really quiet. \"i am a girl...\" she '\n",
      " 'says. some of the other students start saying that their parents made the '\n",
      " 'same mistake when they met sandra. i feel so sorry and stupid. i get the '\n",
      " 'class to calm down and finish taking attendance. we watch the movie in '\n",
      " 'silence. after the movie, when we walked down to where the poster '\n",
      " 'presentation took place i apologised to sandra. i felt so incredibly '\n",
      " 'terrible, i still do to this day. throughout the rest of the day i heard '\n",
      " 'lots of whispers about sandra. i tried to stop them whenever they came up, '\n",
      " 'but there was no stopping the 5th grade gossip i had set in motion.\\n'\n",
      " '\\n'\n",
      " \"sandra, if you're out there, i am so incredibly sorry for humiliating you in \"\n",
      " 'front of your class. i hope you are happy and healthy and continue to live '\n",
      " \"your life the way you like. don't let anyone tell you you have to dress or \"\n",
      " \"act a certain way just because of the body parts you were born with. i'm \"\n",
      " 'sorry if i made you feel like you were wrong for dressing and acting '\n",
      " \"differently. i'm sorry i probably made that day hell for you. i'm sorry for \"\n",
      " 'my ignorance.')\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "pprint(df['documents'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    42139.000000\n",
       "mean       541.585443\n",
       "std        398.646144\n",
       "min          5.000000\n",
       "25%        291.000000\n",
       "50%        439.000000\n",
       "75%        670.000000\n",
       "90%        983.000000\n",
       "95%       1249.000000\n",
       "99%       2028.000000\n",
       "max       8989.000000\n",
       "Name: input_ids, dtype: float64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Give me the percentiles of length of input_ids using pandas and plot them\n",
    "df['input_ids'].apply(len).describe(percentiles=[0.25, 0.5, 0.75, 0.9, 0.95, 0.99])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    42139.000000\n",
       "mean        30.848098\n",
       "std         18.103418\n",
       "min          2.000000\n",
       "25%         19.000000\n",
       "50%         27.000000\n",
       "75%         38.000000\n",
       "90%         52.000000\n",
       "95%         62.000000\n",
       "99%         90.000000\n",
       "max        621.000000\n",
       "Name: labels, dtype: float64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The same for the labels\n",
    "df['labels'].apply(len).describe(percentiles=[0.25, 0.5, 0.75, 0.9, 0.95, 0.99])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pavlosEnv2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
